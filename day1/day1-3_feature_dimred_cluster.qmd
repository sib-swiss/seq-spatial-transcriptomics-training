---
title: "Exercise 3"
format: html
editor: source
editor_options: 
  chunk_output_type: console
---

## Normalisation, Feature Selection and Dimensionality Reduction

In this section we will focus on normalisation, feature selection and dimensionality reduction of spatial transcriptomics data, which are important preprocessing steps before downstream analysis such as clustering and marker gene identification. We will focus on the specific challenges and considerations when dealing with spatially-resolved transcriptomics data, as opposed to traditional single-cell RNA-seq data.

## Learning Objectives

By the end of this exercise, you will be able to:

-   Normalize spatial transcriptomics data to account for technical variations.
-   Perform feature selection to identify highly variable genes (HVGs).
-   Apply dimensionality reduction techniques like PCA.
-   Visualize the results of dimensionality reduction in both reduced dimension space and spatial context.

## Libraries

```{r}
#| message: false
#| warning: false
#| output: false

library(SpatialExperiment)
library(scran) 
library(scater) 
library(ggplot2)
library(patchwork) 
library(bluster)
library(escheR) 
library(pheatmap)
library(HDF5Array) 
library(ggspavis)
library(nnSVG)
library(Banksy)
library(igraph)
```

## Load SpatialExperiment Object

We will start by loading the `SpatialExperiment` object from the previous exercise, which contains only filtered spots and genes with more than 1 count across all spots.

```{r}
# Load the SpatialExperiment object from the .qs2 file.
spe <- loadHDF5SummarizedExperiment(dir="results/day1/", prefix="01.2_spe")
```

## Normalization

Normalization is a critical step in preprocessing spatial transcriptomics data to account for technical variations and make gene expression levels comparable across spots. We will log normalise raw counts with `scuttle::logNormCounts()`

```{r}
# Log-normalize counts for downstream analysis
spe <- logNormCounts(spe)
```

::: callout-important
## Exercise 1
What is the name of the new assay added for normalized counts?
:::

::: {.callout-tip collapse="true"}
### Answer
```{r}
# Have a look at the assays
spe@assays
# Directly get the assay names(x)
assayNames(spe)
```
:::


After log-normalization, we can inspect the computed size factors. Size factors are used to account for differences in sequencing depth between spots.

```{r}
# Display a summary of the calculated size factors.
summary(sizeFactors(spe))

# Visualise the spatial distribution of size factors on the tissue slide.
colData(spe)$sizeFactors <- sizeFactors(spe)
plotVisium(spe, annotate = "sizeFactors", zoom = TRUE, point_shape = 22)
```

::: callout-important
## Exercise 2
Based on the spatial distribution of size factors, do you observe any spatial patterns or gradients across the tissue section? Do you think they reflect technical or biological patterns?
:::

## Feature Selection

### Highly Variable Genes (HVGs)

Feature selection is a crucial step to reduce noise and focus on genes that show significant biological variation across spots. We typically identify Highly Variable Genes (HVGs) as these are more likely to distinguish different cell types or spatial domains.

Before defining the top HVG, we will remove mitochondrial genes, since those genes tend to be highly variable and often not of biological interest.

```{r}
# identify mitochondrial genes
nm <- rowData(spe)$Symbol
mt <- grepl("^MT-", nm, ignore.case = TRUE)
table(mt)
# remove them
spe <- spe[!mt, ]
```

In order to identify HVGs, we will first model the gene variance using a Poisson noise model with `scran::modelGeneVarByPoisson()`

```{r}
# Model gene variance to identify highly variable genes.
# This function fits a mean-variance trend to the log-normalized counts.
dec <- modelGeneVarByPoisson(spe)

# Visualize the mean-variance relationship and the fitted trend.
# This plot helps to understand how gene variability changes with expression level.
plot(dec$mean, dec$total,
  xlab = "Mean expression (log-counts)",
  ylab = "Total variance (log-counts)",
  main = "Mean-Variance Trend"
)
curve(metadata(dec)$trend(x), add = TRUE, col = "dodgerblue", lwd = 2)
```

Once we have modelled the gene variance, we can proceed to select the top HVGs. 
For demonstration purposes, we will select the top 5 HVGs and visualise their expression patterns on the tissue slide.

```{r}
# Top 5 HVGs
top_HVG <- row.names(dec[order(dec$bio, decreasing = T), ])[1:5]
top_HVG

# Create a plot for each gene in top_HVG
ps <- lapply(top_HVG, \(.) {
    plotCoords(spe, 
        annotate = ., 
        assay_name = "logcounts") }) # use "logcounts" assay to visualise log normalised counts

# figure arrangement and change colors
patchwork::wrap_plots(ps, nrow = 2) & 
  theme(legend.key.width = unit(0.4, "lines"), 
        legend.key.height = unit(0.8, "lines")) & 
  scale_color_gradientn(colors = rev(hcl.colors(9, "Rocket")))
```

For downstream analysis, define a larger group of HVG and add the information of whether a genes is in the HVG list or not in rowData

```{r}
# Select the top N highly variable genes.
# The number of HVGs can influence downstream dimensionality reduction and clustering.
hvg <- getTopHVGs(dec, n = 2000) # Selecting top 2000 HVGs

# Store HVG information in rowData
rowData(spe)$hvg <- rowData(spe)$Symbol %in% hvg

# Display the number of HVGs identified
sum(rowData(spe)$hvg)

# Have a look a the new column added
rowData(spe)
```


## Dimensionality Reduction (DR)
Once we have identified highly variable genes (HVGs), we can proceed to perform dimensionality reduction and later on clustering.

### Non-spatially aware DR:

#### PCA

We can perform dimensionality reduction using Principal Component Analysis (PCA) on the log-normalized expression values of the HVGs. This method is agnostic to spatial information, and focuses solely on capturing the main axes of variation in the gene expression data.

```{r}
# Run PCA on the log-normalized counts of the HVGs
spe <- runPCA(spe, ncomponents = 30, subset_row = rowData(spe)$hvg)

# Visualize the explained variance by each principal component.
# This helps in determining how many PCs capture most of the variance.
plot(attr(reducedDim(spe, "PCA"), "percentVar"),
  xlab = "PC", ylab = "Proportion of variance explained",
  main = "PCA Scree Plot"
)
```

::: callout-important
## Exercise 3
Based on the scree plot, how many principal components would you consider for downstream analysis? Why?
:::

::: {.callout-tip collapse="true"}
### Answer
We can select the first 10 PCs for downstream analysis, as they capture a significant proportion of the variance in the data before the explained variance starts to level off.
::: 

Choose the number of PCs accordingly for downstream analysis. Visualize the PCs on the tissue slice coordinates.

```{r}
# Run PCA on the log-normalized counts of the HVGs using 10 PCs
spe <- runPCA(spe, ncomponents = 10, subset_row = rowData(spe)$hvg)

# Get the PCA results 
pcs <- reducedDim(spe, "PCA")
# Visualize PCs on the tissue slice coordinates
ps <- lapply(colnames(pcs), \(.) {
    spe[[.]] <- pcs[, .]
    plotCoords(spe, annotate = .)
}) 
# Arrange the plots and customize colors
patchwork::wrap_plots(ps, nrow = 2) & 
  theme(legend.key.width = unit(0.4, "lines"), 
        legend.key.height = unit(0.8, "lines")) & 
  scale_color_gradientn(colors = rev(hcl.colors(9, "Rocket")))

```

### Spatially aware DR:

#### Banksy

We can also perform spatially aware dimensionality reduction using the `Banksy` method, which integrates spatial coordinates and gene expression into the PCA framework. This allows us to capture spatial patterns in the data while reducing dimensionality. 

```{r}
# Clustering with Banksy
set.seed(112358)

# 'Banksy' parameter settings
k <- 20   # consider first order neighbors
l <- 0.8 # use spatial information with weight lambda
a <- "logcounts" # assay to use
xy <- c("array_row", "array_col")  # spatial coordinate names

# restrict to selected HVG features
dec <- modelGeneVarByPoisson(spe)
hvg <- getTopHVGs(dec, n = 2000) # Selecting top 2000 HVGs
tmp <- spe[hvg, ] # subset to HVGs

# compute spatially aware 'Banksy' PCs
tmp <- computeBanksy(tmp, assay_name=a, coord_names=xy, k_geom=k)
tmp <- runBanksyPCA(tmp, lambda=l, npcs=10)
reducedDim(spe, "PCA_banksy") <- reducedDim(tmp) # store 'Banksy' PCs in original object
```

::: callout-important
## Exercise 4
Have a look at the spe object to see the dimensionality reduction slots. How many dimensionality reductions are stored now? What are their names and what do they represnt?
:::

::: {.callout-tip collapse="true"}
### Answer

```{r}
spe
reducedDimNames(spe)
```

There are now three dimensionality reductions stored in the `spe` object: :"PCA_artifacts", "PCA" and "PCA_banksy". "PCA_artifacts" was computed to capture technical artifacts in a previous exercise (QC step).

"PCA" represents the non-spatially aware principal components, while "PCA_banksy" represents the spatially aware principal components computed using the Banksy method. Both methods have used HVGs for dimensionality reduction.
:::

In the same way as before, we can visualise the Banksy PCs on the tissue slice coordinates.

::: callout-important
## Exercise 5
Select pcs from Banksy dimensionality reduction space and visualise them on the tissue slice. Do you observe any spatial patterns? How do they compare to the non-spatial PCA?
:::

::: {.callout-tip collapse="true"}
### Answer

```{r}
## Visualize PCs on the tissue slice coordinates
pcs <- reducedDim(spe, "PCA_banksy")
#pcs <- pcs[, seq_len(10)]
ps <- lapply(colnames(pcs), \(.) {
    spe[[.]] <- pcs[, .]
    plotCoords(spe, annotate = .)
}) 
patchwork::wrap_plots(ps, nrow = 2) & 
  theme(legend.key.width = unit(0.4, "lines"), 
        legend.key.height = unit(0.8, "lines")) & 
  scale_color_gradientn(colors = rev(hcl.colors(9, "Rocket")))
```
:::


::: callout-important
## Bonus Exercise
Try to change Banksy parameters k and lambda, how it affects the results?
:::


## Run UMAP

Run UMAP (for visualization purposes only) based on both, spatially aware and not spatially aware dimensionality reduction

```{r}
# UMAP
spe <- runUMAP(spe, dimred="PCA", name="UMAP_tx")
spe <- runUMAP(spe, dimred="PCA_banksy", name="UMAP_banksy")
```

```{r}
# Visualise
plotReducedDim(spe, dimred = "UMAP_tx", colour_by = "sum") 
plotReducedDim(spe, dimred = "UMAP_banksy", colour_by = "sum")
```


::: callout-important
## Bonus question
If you tried different parameters for Banksy, how does it affect the UMAP results?
:::


## Save data for later

```{r}
spe_HVG <- spe
saveHDF5SummarizedExperiment(spe_HVG, dir="results/day1", prefix="01.3_spe", replace=TRUE,
                                chunkdim=NULL, level=NULL, as.sparse=NA,
                                verbose=NA)
```

### Spatially-Aware Normalization (Optional)
While `logNormCounts` provides a general-purpose normalization, specialized spatially-aware normalization methods exist (e.g., `SpaNorm` package). These methods aim to correct for technical variations while preserving true spatial biological patterns. Depending on the dataset and research question, exploring such advanced normalization techniques might be beneficial.



