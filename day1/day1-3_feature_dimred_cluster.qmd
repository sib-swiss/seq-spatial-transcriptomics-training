---
title: "Exercise 3"
format: html
editor: source
editor_options: 
  chunk_output_type: console
---

> Juna: This part needs to be updated

## Feature Selection, Dimensionality Reduction, and Clustering

In this third exercise, we will explore the essential techniques of feature selection, dimensionality reduction, and clustering to uncover meaningful biological insights from spatial transcriptomics data. We will learn how to identify the most informative genes, visualize complex high-dimensional data in lower-dimensional spaces using methods like PCA and UMAP, and group spots into clusters representing distinct spatial domains. These steps are fundamental for interpreting the underlying biological structure of the tissue.

## Learning Objectives

By the end of this exercise, you will be able to:

-   Perform feature selection to identify highly variable genes (HVGs).
-   Apply dimensionality reduction techniques like PCA and UMAP.
-   Perform clustering to identify distinct spatial domains or cell populations.
-   Visualize the results of dimensionality reduction and clustering in both reduced dimension space and spatial context.

## Libraries

```{r}
#| message: false
#| warning: false
#| output: false

library(SpatialExperiment)
library(scran) 
library(scater) 
library(ggplot2)
library(patchwork) 
library(bluster)
library(escheR) 
library(pheatmap)
library(HDF5Array) 
library(ggspavis)
library(nnSVG)
library(Banksy)
```

## Load SpatialExperiment Object

We will start by loading the `SpatialExperiment` object from the previous exercise, which contains only filtered spots and genes with more than 1 count across all spots.

```{r}
# Load the SpatialExperiment object from the .qs2 file.
spe <- loadHDF5SummarizedExperiment(dir="results/day1/", prefix="01.2_spe")
```

## Normalization

Normalization is a critical step in preprocessing spatial transcriptomics data to account for technical variations and make gene expression levels comparable across spots. We will log normalise raw counts with `scuttle::logNormCounts()`

```{r}
# Log-normalize counts for downstream analysis
spe <- logNormCounts(spe)
```

**Question 1: What is the name of the new assay added for normalized counts?**

::: {.callout-tip collapse="true"}
### Answer
```{r}
# Have a look at the assays
spe@assays
# Directly get the assay names(x)
assayNames(spe)
```
:::


After log-normalization, we can inspect the computed size factors. Size factors are used to account for differences in sequencing depth between spots.

```{r}
# Display a summary of the calculated size factors.
summary(sizeFactors(spe))

# Visualise the spatial distribution of size factors on the tissue slide.
colData(spe)$sizeFactors <- sizeFactors(spe)
plotVisium(spe, annotate = "sizeFactors", zoom = TRUE, point_shape = 22)
```

**Question 2: Based on the spatial distribution of size factors, do you observe any spatial patterns or gradients across the tissue section? Do you think they reflect technical or biological patterns?**


## Feature Selection

### Highly Variable Genes (HVGs)

Feature selection is a crucial step to reduce noise and focus on genes that show significant biological variation across spots. We typically identify Highly Variable Genes (HVGs) as these are more likely to distinguish different cell types or spatial domains.

Before defining the top HVG, we will remove mitochondrial genes, since those genes tend to be highly variable and often not of biological interest.

```{r}
# identify mitochondrial genes
nm <- rowData(spe)$Symbol
mt <- grepl("^MT-", nm, ignore.case = TRUE)
table(mt)
# remove them
spe <- spe[!mt, ]
```

In order to identify HVGs, we will first model the gene variance using a Poisson noise model with `scran::modelGeneVarByPoisson()`

```{r}
# Model gene variance to identify highly variable genes.
# This function fits a mean-variance trend to the log-normalized counts.
dec <- modelGeneVarByPoisson(spe)

# Visualize the mean-variance relationship and the fitted trend.
# This plot helps to understand how gene variability changes with expression level.
plot(dec$mean, dec$total,
  xlab = "Mean expression (log-counts)",
  ylab = "Total variance (log-counts)",
  main = "Mean-Variance Trend"
)
curve(metadata(dec)$trend(x), add = TRUE, col = "dodgerblue", lwd = 2)
```

Once we have modelled the gene variance, we can proceed to select the top HVGs. 
For demonstration purposes, we will select the top 5 HVGs and visualise their expression patterns on the tissue slide.

```{r}
# Top 5 HVGs
top_HVG <- row.names(dec[order(dec$bio, decreasing = T), ])[1:5]
top_HVG

# Create a plot for each gene in top_HVG
ps <- lapply(top_HVG, \(.) {
    plotCoords(spe, 
        annotate = ., 
        assay_name = "logcounts") }) # use "logcounts" assay to visualise log normalised counts

# figure arrangement and change colors
patchwork::wrap_plots(ps, nrow = 2) & 
  theme(legend.key.width = unit(0.4, "lines"), 
        legend.key.height = unit(0.8, "lines")) & 
  scale_color_gradientn(colors = rev(hcl.colors(9, "Rocket")))
```

For downstream analysis, define a larger group of HVG and add the information of whether a genes is in the HVG list or not in rowData

```{r}
# Select the top N highly variable genes.
# The number of HVGs can influence downstream dimensionality reduction and clustering.
hvg <- getTopHVGs(dec, n = 2000) # Selecting top 2000 HVGs

# Store HVG information in rowData
rowData(spe)$hvg <- rowData(spe)$Symbol %in% hvg

# Display the number of HVGs identified
sum(rowData(spe)$hvg)

# Have a look a the new column added
rowData(spe)
```

## Save data for later

```{r}
spe_HVG <- spe
saveHDF5SummarizedExperiment(spe_HVG, dir="results/day1", prefix="01.3_spe_tmp", replace=TRUE,
                                chunkdim=NULL, level=NULL, as.sparse=NA,
                                verbose=NA)

#To avoid large computational time, we will subset the dataset to the HVG
tmp <- spe[hvg, ]
saveHDF5SummarizedExperiment(tmp, dir="results/day1", prefix="01.3_spe_tmp_tmp", replace=TRUE,
                                chunkdim=NULL, level=NULL, as.sparse=NA,
                                verbose=NA)

```

### Spatially-Aware Normalization (Optional)
While `logNormCounts` provides a general-purpose normalization, specialized spatially-aware normalization methods exist (e.g., `SpaNorm` package). These methods aim to correct for technical variations while preserving true spatial biological patterns. Depending on the dataset and research question, exploring such advanced normalization techniques might be beneficial.